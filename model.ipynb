{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from keras.layers import Conv2D, Dense, Layer, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.activations import sigmoid\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import RIG\n",
    "import random\n",
    "import os\n",
    "from keras.constraints import unitnorm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Preprocessing Functions\n",
    "img_dim = 64\n",
    "def trim(img_array, img_w=img_dim, img_h=img_dim):\n",
    "    return img_array[img_array.shape[0]//2 - img_w//2:img_array.shape[0]//2 + img_w//2, img_array.shape[1]//2 - img_h//2: img_array.shape[1]//2 + img_h//2]\n",
    "def couple(img_array1, img_array2):\n",
    "    return np.concatenate([img_array1, img_array2], axis=0)\n",
    "def add_margin(pil_img, top, right, bottom, left, color):\n",
    "    width, height = pil_img.size\n",
    "    new_width = width + right + left\n",
    "    new_height = height + top + bottom\n",
    "    result = Image.new(pil_img.mode, (new_width, new_height), color)\n",
    "    if new_height%2 == 1:\n",
    "        result = Image.new(pil_img.mode, (new_width, new_height+1), color)\n",
    "    if new_width%2 == 1:\n",
    "        result = Image.new(pil_img.mode, (new_width+1, new_height), color)\n",
    "    result.paste(pil_img, (left, top))\n",
    "    return result\n",
    "def face(img):\n",
    "    img = np.array(img)\n",
    "    #Change this to where your csv installation is located\n",
    "    cv2_path = 'ml/lib/python3.10/site-packages/cv2/'\n",
    "    face_cascade = cv2.CascadeClassifier(os.path.join(cv2_path, 'data/haarcascade_frontalface_default.xml'))\n",
    "    faces = face_cascade.detectMultiScale(img, 1.1, 4)\n",
    "    for (x, y, w, h) in faces:\n",
    "        if y < img.shape[0] and x < img.shape[1]:\n",
    "            if y+h < img.shape[0]:\n",
    "                if x+w < img.shape[1]:\n",
    "                    img = img[y:y + h, x:x + w]\n",
    "                else:\n",
    "                    img = img[y:y+h, x:]\n",
    "            else:\n",
    "                if x+w < img.shape[1]:\n",
    "                    img = img[y:, x:x + w]\n",
    "                else:\n",
    "                    img = img[y:, x:]\n",
    "    return Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom Layers\n",
    "\n",
    "class Decouple(Layer):\n",
    "    def __init__(self, size=img_dim):\n",
    "        super(Decouple, self).__init__()\n",
    "        self.size = size\n",
    "    def call(self, inputs):\n",
    "        return tf.concat([inputs[:, :self.size], inputs[:, inputs.shape[1]-self.size:]], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Populate Directory with Similars\n",
    "\n",
    "with open(\"celebrities.txt\") as f:\n",
    "    celebs = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "for celeb in celebs:\n",
    "    RIG.store(query=celeb, dir=\"similars\", quantity=2, store_keys=True, csv_path=\"references.csv\", value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Populate Directory with Dissimilars(random)\n",
    "\n",
    "#Returns the lengths of each file for the name generator\n",
    "length_dict = {}\n",
    "for file in os.listdir(\"curate\"):\n",
    "    path = os.path.join(\"curate\", file)\n",
    "    f = open(path)\n",
    "    length_dict[file] = len(f.readlines())\n",
    "f.close()\n",
    "\n",
    "#Name Generator\n",
    "num_names = 1000\n",
    "name_indices = random.sample(range(51075960), num_names)\n",
    "name_indices.sort()\n",
    "sum = 0\n",
    "i = -1\n",
    "for index in name_indices:\n",
    "    while sum < index:\n",
    "        i += 1\n",
    "        f = open(os.path.join(\"curate\", list(length_dict.keys())[i]))\n",
    "        current = f.readlines()\n",
    "        f.close()\n",
    "        sum += list(length_dict.values())[i]\n",
    "    RIG.store(query=current[sum-index].split(\",\")[slice(2)], dir=\"similars\", quantity=2, store_keys=True, csv_path=\"references.csv\", value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Populate Directory with Dissimilars(celebrities)\n",
    "\n",
    "with open(\"celebrities.txt\") as f:\n",
    "    celebs = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "#Form Random Pairs\n",
    "pairs = []\n",
    "num_pairs = 350\n",
    "name_indices = random.sample(range(len(celebs)), 2*num_pairs)\n",
    "for i in range(0, num_pairs, 2):\n",
    "    pairs.append([celebs[name_indices[i]], celebs[name_indices[i+1]]])\n",
    "\n",
    "for pair in pairs:\n",
    "    RIG.store_multiple(query_list=pair, dir=\"similars\", quantity=1, store_keys=True, csv_path=\"references.csv\", value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle References\n",
    "with open(\"references.csv\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "with open(\"references.csv\", \"w\") as f:\n",
    "    random.shuffle(lines)\n",
    "    f.writelines(lines)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Organizing Data\n",
    "\n",
    "dir = \"similars\"\n",
    "with open(\"references.csv\") as f:\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "train_targets = []\n",
    "train_imgs = []\n",
    "for i in lines[:]:\n",
    "    splitted = i.split(\",\")\n",
    "    train_targets.append(float(splitted[0]))\n",
    "    img1 = Image.open(f\"{dir}/{splitted[1]}.jpg\")\n",
    "    img2 = Image.open(f\"{dir}/{splitted[2][:-1]}.jpg\")\n",
    "    imgs = [img1, img2]\n",
    "    img1 = face(img1)\n",
    "    img2 = face(img2)\n",
    "    if img1.size[0] < img_dim:\n",
    "        img1 = add_margin(img1, 0, (img_dim-img1.size[0])//2, 0, (img_dim-img1.size[0])//2, (0, 0, 0))\n",
    "    if img1.size[1] < img_dim:\n",
    "        img1 = add_margin(img1, (img_dim-img1.size[1])//2, 0, (img_dim-img1.size[1])//2, 0, (0, 0, 0))\n",
    "    if img2.size[0] < img_dim:\n",
    "        img2 = add_margin(img2, 0, (img_dim-img2.size[0])//2, 0, (img_dim-img2.size[0])//2, (0, 0, 0))\n",
    "    if img2.size[1] < img_dim:\n",
    "        img2 = add_margin(img2, (img_dim-img2.size[1])//2, 0, (img_dim-img2.size[1])//2, 0, (0, 0, 0))\n",
    "    train_imgs.append(couple(trim(np.array(img1)), trim(np.array(img2))))\n",
    "train_targets = np.array(train_targets)\n",
    "train_imgs = np.float32(np.array(train_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Collection\n",
    "\n",
    "#Think of interchanging some Convolution Layers with Pooling Layers\n",
    "\n",
    "class Models(Sequential):\n",
    "    def __init__(self):\n",
    "        super(Models, self).__init__()\n",
    "    def reduction(self):\n",
    "        self.add(Conv2D(10, (img_dim//2, img_dim//2), use_bias=False))\n",
    "        self.add(Decouple(img_dim//2+1))\n",
    "        self.add(Conv2D(1, (img_dim//4, img_dim//4), use_bias=False))\n",
    "        self.add(Decouple(img_dim//4+2))\n",
    "        self.add(Conv2D(1, (img_dim//4, img_dim//4), use_bias=False))\n",
    "        self.add(Decouple(3))\n",
    "        self.add(Conv2D(10, (2, 2), use_bias=False))\n",
    "        self.add(Decouple(2))\n",
    "        self.add(Conv2D(1, (2, 2), use_bias=False))\n",
    "        self.add(Decouple(1))\n",
    "        self.add(Flatten())\n",
    "        self.add(Dense(32, use_bias=False))\n",
    "        self.add(Dense(1, activation=sigmoid, bias_constraint=unitnorm()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training a Model\n",
    "model = Models()\n",
    "model.reduction()\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "history = model.fit(x=train_imgs, y=train_targets, epochs=100, batch_size=32, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation\n",
    "\n",
    "img1 = Image.open(f\"1.jpg\")\n",
    "img2 = Image.open(f\"2.jpg\")\n",
    "img1 = face(img1)\n",
    "img2 = face(img2)\n",
    "if img1.size[0] < img_dim:\n",
    "    img1 = add_margin(img1, 0, (img_dim-img1.size[0])//2, 0, (img_dim-img1.size[0])//2, (0, 0, 0))\n",
    "if img1.size[1] < img_dim:\n",
    "    img1 = add_margin(img1, (img_dim-img1.size[1])//2, 0, (img_dim-img1.size[1])//2, 0, (0, 0, 0))\n",
    "if img2.size[0] < img_dim:\n",
    "    img2 = add_margin(img2, 0, (img_dim-img2.size[0])//2, 0, (img_dim-img2.size[0])//2, (0, 0, 0))\n",
    "if img2.size[1] < img_dim:\n",
    "    img2 = add_margin(img2, (img_dim-img2.size[1])//2, 0, (img_dim-img2.size[1])//2, 0, (0, 0, 0))\n",
    "datum = couple(trim(np.array(img1)), trim(np.array(img2)))\n",
    "#Image.fromarray(datum).show()\n",
    "model.predict(np.array([datum]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Model Weights\n",
    "model.save_weights(\"weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Model Weights\n",
    "'''\n",
    "model: \"reduction\", weights: \"weights\", img_dim=64\n",
    "model: \"reduction_alt\", weights: \"weights_alt\", img_dim=64\n",
    "'''\n",
    "model = Models()\n",
    "model.reduction()\n",
    "model.build(input_shape=(None, img_dim*2, img_dim, 3))\n",
    "model.load_weights(\"weights\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f89f43c1ceb8498550e9f7faae61caa6466df2058474e36a502e98c7118663dd"
  },
  "kernelspec": {
   "display_name": "Python 3.10.9 ('ml': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
